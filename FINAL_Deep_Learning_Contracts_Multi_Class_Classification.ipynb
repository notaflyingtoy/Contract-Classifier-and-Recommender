{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL Deep Learning - Contracts Multi-Class Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0202d1dca65c4ea080a32ee279bab6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_465c5632201146fda431b438799bd287",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e70693c7df5e47bdb912b19df7df696f",
              "IPY_MODEL_e078ecbf5810444888c9aa2024884cfe"
            ]
          }
        },
        "465c5632201146fda431b438799bd287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e70693c7df5e47bdb912b19df7df696f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf5d863ac0184d9e8c2a97a00162242d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5e7b9678cf5474c9b3bf869fb299ca1"
          }
        },
        "e078ecbf5810444888c9aa2024884cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b11d1a13684d4d038b7a0a36dfedd4c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.59kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6255e93757e47c3a3f26716c8328cc3"
          }
        },
        "cf5d863ac0184d9e8c2a97a00162242d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5e7b9678cf5474c9b3bf869fb299ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b11d1a13684d4d038b7a0a36dfedd4c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6255e93757e47c3a3f26716c8328cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50240b264003435fa9016827f9ceb487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4550873bf0364a138fe98687bf1498bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23ecfd2b5f31424386ecb51105152643",
              "IPY_MODEL_4879be5025224fac8accdd11cc1ac6ad"
            ]
          }
        },
        "4550873bf0364a138fe98687bf1498bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23ecfd2b5f31424386ecb51105152643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ae2f0ff5a3c41f5873b032cf06467eb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78909ffffe344a359ca265b377afe721"
          }
        },
        "4879be5025224fac8accdd11cc1ac6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8dbc1dca607d4775ae3a1fce0a1fcbb8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:17&lt;00:00, 13.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89881ebe0d824afd888f4757214e304a"
          }
        },
        "5ae2f0ff5a3c41f5873b032cf06467eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78909ffffe344a359ca265b377afe721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8dbc1dca607d4775ae3a1fce0a1fcbb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89881ebe0d824afd888f4757214e304a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2dd653f6ba54d4ab9753b94e517c523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_263a8a77d1324d6e89ebaf5460124919",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0571117c5d1c4f3bac129471c8861dac",
              "IPY_MODEL_5b13e1a161fd47ae9c30c2c6c3c37d14"
            ]
          }
        },
        "263a8a77d1324d6e89ebaf5460124919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0571117c5d1c4f3bac129471c8861dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b90ec8175e3d4fd6bfb23dc35cc1040a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73c8f72e22b74e4da04c73380dfd99ea"
          }
        },
        "5b13e1a161fd47ae9c30c2c6c3c37d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_744f89110c7545bd8fd615065d535c11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 662kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b7be642f7964c76b70ca3b8f3801c57"
          }
        },
        "b90ec8175e3d4fd6bfb23dc35cc1040a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73c8f72e22b74e4da04c73380dfd99ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "744f89110c7545bd8fd615065d535c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b7be642f7964c76b70ca3b8f3801c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a0614461b8e4288b8b66785ef5c405d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5916eed760c648e5801ce67d3b794ebe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6ced2c02c81142b0bc3512d6f99c957d",
              "IPY_MODEL_52a5c2c0141b45f1950c16883ff2ee0a"
            ]
          }
        },
        "5916eed760c648e5801ce67d3b794ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ced2c02c81142b0bc3512d6f99c957d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d7b00fd546e42278afe570c628aba1b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a005bdf9f4924c40b3764c4f0b25f989"
          }
        },
        "52a5c2c0141b45f1950c16883ff2ee0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bcb240e5d06d4b00aedcd9258c36dab9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 218B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d10207c93bea42a58628e60e66f40d6c"
          }
        },
        "0d7b00fd546e42278afe570c628aba1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a005bdf9f4924c40b3764c4f0b25f989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcb240e5d06d4b00aedcd9258c36dab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d10207c93bea42a58628e60e66f40d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04ccc20b4ab74723a918a680b14bacd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a06adab86952482b981cb1bb9e890246",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aba6584b92df402faadd2e4d0b8a6cc2",
              "IPY_MODEL_1de25366b45f4974bbb9491af4768c16"
            ]
          }
        },
        "a06adab86952482b981cb1bb9e890246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aba6584b92df402faadd2e4d0b8a6cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4724337427e3495bbd5ffd8753083cc1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa015bb2951545c5939d31708b3cd11f"
          }
        },
        "1de25366b45f4974bbb9491af4768c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc8194a57d9144d8bc072f6c2076ad4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:15&lt;00:00, 34.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c40bec67a11c42df997c4d037acf9b88"
          }
        },
        "4724337427e3495bbd5ffd8753083cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa015bb2951545c5939d31708b3cd11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc8194a57d9144d8bc072f6c2076ad4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c40bec67a11c42df997c4d037acf9b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notaflyingtoy/Contract-Classifier-and-Recommender/blob/main/FINAL_Deep_Learning_Contracts_Multi_Class_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRiNtQlSQEbT"
      },
      "source": [
        "##Multi Classification Problem CS987\n",
        "- Team Name - Kerasic Park\n",
        "- Members - Calum Lockhart 202077518, Joshua Murphy 202059689, Luke Hand 202091647, Anant Tyagi 202060104\n",
        "\n",
        "## Overview and Abstract\n",
        "\n",
        "For this multi classification problem, four different kinds of models were made and fitted to data in order to predict the class that a document belonged to.  The four kinds of models used were a standard machine learning one versus rest model, a deep neural network model, a model utilising LSTM and a model using BERT.  After fitting these models to the data a f1 score was calculated for each model and a test score was calculated on Kaggle in order to determine which model was the best for the task.\n",
        "\n",
        "The main finding of our investigation was that the BERT model was the best model out of the four tested as it had a significantly higher score on Kaggle when predicting using the test dataset and it also had the best f1 score. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWf8PAA2TzPL"
      },
      "source": [
        "##Methods\n",
        "\n",
        "##Preprocessing\n",
        "\n",
        "The data was processed differently for the models.  The one versus rest model and the deep neural network used the same preprocessed data.  The data was preprocessed differently for the LSTM model and it was also preprocessed differently again for the BERT model.\n",
        "\n",
        "For the one versus rest and deep neural network models the data was preprocessed by cleaning the text columns of punctuation and special characters.  Stopwords was also used to remove common irrelevant words from these columns.  The most common words in the text columns Title and Description were then transformed into vectors and assigned values between 0 and 1 so that they could be used in the models.  These words were then used as columns of the dataframe.  The city name that was also present in the Title column was dropped.  The columns Country_Name, Country_Code and Sector were all dropped as they only contained 1 value in each column.  The Publication_Date column was encoded and one hot encoding was used for the Contract_Type column.  The Label column that consisted of 9 binary digits was changed into 9 new columns that each contained one of the binary digits.  Lastly, before the data was used in the model it was scaled using a standard scaler.  This was done so that the data could be used in the models.  This same processing was done on the testing set aswell.\n",
        "\n",
        "For the LSTM model the data was processed slightly diffrently.  It should be noted that this model only uses the Title column as input.  Firstly, recycled code was used from a notebook we created that was used to preprocess the data for the first two models.  This was done so that we could quickly get the Title column into a state where it was easy to use Stopwords and clean it of punctuation and special characters.  This column was then transformed using a tokenizer and these tokens were changed into sequences, in order to keep the word placement, and padded so that each input had the same length.  The length chosen was 7 as this seemed like an average length of the titles.  The testing set underwent this this preprocessing also.\n",
        "\n",
        "The preprocessing for the Bert model differed in that only the title column was utilised and it was put into a BERT tokeniser to transform the text input into BERT tokens.\n",
        "\n",
        "After each time the data was preprocessed it was split into a training, validating and testing set.  This was done so that we could check the validation accuracy and also so the f1 scores could be calculated for each of the models.\n",
        "\n",
        "##Models\n",
        "\n",
        "The first model we tested was the baseline standard machine learning model.  For this we chose a one versus rest classifier as it is a standard machine learning multiclass classifier.\n",
        "\n",
        "The second model was a dense deep neural network.  A grid search was utilised in order to get the best parameters for the model.  The model that the grid search returned consisted of 86 neurons per layer with 4 hidden layers and a learning rate of 0.003.  Each of the hidden layers used a Relu activation function.  The output layer consisted of 9 neurons with a Sigmoid activation.  This was because the label consisted of 9 binary elements.  The predictions for this model were rounded to either 1 or 0 as the Sigmoid activation returns values between 0 and 1.\n",
        "\n",
        "The third model that was used was a LSTM that was adapted from reference 1.  This model consists of an input layer, a LSTM layer, a dense layer and a dense output layer with 9 neurons and the Sigmoid activation function.\n",
        "\n",
        "The BERT model implements the pre-trained  “bert-based-uncased\" model, a transformers model trained unsupervised on a large dataset of English text [2,3], thorough the huggingface transformers repository [4].  \n",
        "\n",
        "The BERT model consisted of a shape = (46, ) input as the longest title was 46 words. The test data input was padded with 4 additional zeroes as the longest title in the test dataset was 42 words. Then a “BERT” layer which is actually 12 hidden layers in the transformer encoder and 12 self-attention heads. Next, a dropout layer with a dropout rate of 10% as specified in the configuration of the pre-trained model. Finally, there were 9 binary outputs with a sigmoid activation function.  \n",
        "\n",
        "##Training\n",
        "\n",
        "The training for all of the models consisted of training them on their respective preprocessed data.  This data consisted of a subset of the full training data as some of it was used a validation data and some as testing data for calculation of the f1 scores for the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wPdQuBPP_CK"
      },
      "source": [
        "# Include your packages/imports here.\n",
        "\n",
        "# Add your models here\n",
        "\n",
        "#One versus rest model\n",
        "\n",
        "ovr = OneVsRestClassifier(GaussianNB())\n",
        "\n",
        "#Deep neural network model with best parameters from grid search\n",
        "\n",
        "deep_model_best_param = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[1289]),\n",
        "    keras.layers.Dense(86, activation=\"relu\"),\n",
        "    keras.layers.Dense(86, activation=\"relu\"),\n",
        "    keras.layers.Dense(86, activation=\"relu\"),\n",
        "    keras.layers.Dense(86, activation=\"relu\"),\n",
        "    keras.layers.Dense(9, activation=\"sigmoid\")     \n",
        "])\n",
        "\n",
        "#LSTM model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
        "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(9, activation='sigmoid')\n",
        "])\n",
        "\n",
        "#BERT model\n",
        "\n",
        "\n",
        "# Add your functions for training here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsHg6AEZ0iVU"
      },
      "source": [
        "##Results\n",
        "\n",
        "![Screenshot 2021-04-11 174654.png](data:image/png;base64,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)\n",
        "\n",
        "The table above shows each of the scores that the models got.  The one versus rest and deep neural network models both got similar f1 scores of around 0.6 but the deep neural network got a significantly better score on Kaggle.  The LSTM and BERT models both got very good f1 scores of around 0.95.  On Kaggle the BERT model achieved a score of 0.92204 which was the highest score that the models got.  The LSTM model however only manage to achieve a score of 0.51947, which was the lowest score out of the models.\n",
        "\n",
        "We found that the most important features were the text features, specifically the Title column.  This is because BERT managed to get a very good score using only the Title column and LSTM managed to get a very good f1 score also using only the Title column in comparison to the other models that used a lot more of the data features.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78EX9ap-FNxy"
      },
      "source": [
        "##Summary\n",
        "\n",
        "The recommended model is the BERT model because it had the highest f1 score and Kaggle score.  It should be noted though that this model takes a considerable amount of time to train comapared to the other models however.  When implementing the chosen model, it may be worth considering adapting it for online learning to enable it to capitalise on the continual flow of information from the tenders collated by BIP Solutions and thus deliver more accurate results.  While BERT has been shown to have some cross language applications, particularly in classification tasks [5], further training could be performed using the relevant monolingual form of BERT. \n",
        "\n",
        "The other model that may be worth consideration is the LSTM model as this had a very good f1 score comparable with the BERT model but did not get nearly as good a score on Kaggle.  This could be due to the fact that it was only fitted using the Title column so if it were run with more input data or concatenated together with another model that took the numerical data as input, there is potential that it could get a much better overall score on Kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qh9x2K_RW_P"
      },
      "source": [
        "# References\n",
        "\n",
        "[1] - Multi Class Text Classification with LSTM using TensorFlow 2.0 \n",
        "       - Susan Li\n",
        "    - https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35\n",
        "      \n",
        "\n",
        "[2] - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding - J.Devlin, M.Chang, K.Lee, K.Toutanova \n",
        "    - https://arxiv.org/pdf/1810.04805.pdf \n",
        "\n",
        "[3] - Multi-Label, Multi-Class Text Classification with BERT, Transformers and Keras - Emil Lykke Jensen \n",
        "    - https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a \n",
        "\n",
        "[4] - Transformers: State-of-the-Art Natural Language Processing\n",
        "    - https://github.com/huggingface/transformers\n",
        "\n",
        "[5] - Is Multilingual BERT Fluent in Language Generation? - S.Ronnqvist, J.Kanerva, T.Salakoski, F.Ginter\n",
        "    - https://www.aclweb.org/anthology/W19-6204.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXtZ3k88RZ9o"
      },
      "source": [
        "# Code\n",
        "\n",
        "Feature Processing\n",
        "- Report how your processed the data here or in a separate notebook (provide link if a separate notebook is used).\n",
        "\n",
        "Training and Validating etc.\n",
        "- Show your working here – where you report all your training and validation, etc. that you performed in order to get the results.\n",
        "- Note that it is important that you results can be replicated. All code to reproduce the final predictions must be included, along with any code that justifies your choices.\n",
        "\n",
        "Any Additional Analysis\n",
        "- Add in any additional analysis etc that you performed here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBmmfO2tNJaf"
      },
      "source": [
        "##Code for One Versus Rest and Deep Neural Network models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M6W86ZFR0yI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f71e960-23e8-475b-b260-ddca26a73a55"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import GermanStemmer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import datetime\n",
        "\n",
        "import sklearn\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#from nltk.stem.api import StemmerI\n",
        "en_stm = WordNetLemmatizer()\n",
        "de_stm = GermanStemmer()\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njAbq_vaNWaw"
      },
      "source": [
        "train = pd.read_csv('/content/german-contracts-train.csv')\n",
        "test = pd.read_csv('/content/german-contracts-test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpYsMFFVNYX4"
      },
      "source": [
        "stop_words = stopwords.words(['german','english'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUmYFV_mNdHv"
      },
      "source": [
        "def split_right(s):\n",
        "  n = s.find(':')\n",
        "  a = s[n+1:]\n",
        "  return a\n",
        "\n",
        "def split_left(s):\n",
        "  n = s.find(':')\n",
        "  a = s[:n]\n",
        "  return a\n",
        "\n",
        "def OHE(df, col):\n",
        "  # one hot encode column (col) in dataframe (df) then replace original column \n",
        "  # with one hot encoded column\n",
        "  ohe = OneHotEncoder(sparse = False)\n",
        "  ohe_values = ohe.fit_transform(df[[col]])\n",
        "  ohe_cols = [col + '_' + s for s in ohe.categories_]\n",
        "  df_ohe_values = pd.DataFrame(ohe_values,\n",
        "                               columns = np.ndarray.flatten(np.array(ohe_cols)))\n",
        "  df = pd.concat((df, df_ohe_values), axis = 1)\n",
        "  df = df.drop(col, axis = 1)\n",
        "  return df\n",
        "\n",
        "  \n",
        "#Code taken from https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff\n",
        "#Removing all the punctuation from the title column\n",
        "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
        "  cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "  cleaned = re.sub(r'[.|,|)|(|\\|/|-]',r' ',cleaned)\n",
        "  cleaned = cleaned.strip()\n",
        "  cleaned = cleaned.replace(\"\\n\",\" \")\n",
        "  return cleaned\n",
        "\n",
        "def stemSentence(sentence):\n",
        "  token_words=word_tokenize(sentence)\n",
        "  token_words\n",
        "  stem_sentence=[]\n",
        "  for word in token_words:\n",
        "    # stem/lemmatize words in german & english\n",
        "    stem_sentence.append(de_stm.stem(en_stm.lemmatize(word)))\n",
        "    stem_sentence.append(\" \")\n",
        "  return \"\".join(stem_sentence)\n",
        "\n",
        "def fit_vectorizer(df1, df2, col, min_df):\n",
        "  df = df1.append(df2)\n",
        "  vectorizer = TfidfVectorizer(min_df=min_df, \n",
        "                               norm='l2', \n",
        "                               strip_accents = 'unicode',  \n",
        "                               ngram_range=(1, 2), \n",
        "                               analyzer = 'word',\n",
        "                               lowercase= True)\n",
        "  vectorizer.fit(df[col])\n",
        "  return vectorizer\n",
        "\n",
        "def vectorise_col(df, col, vectorizer):\n",
        "  #vectorizer = TfidfVectorizer(min_df=min_df, \n",
        "  #                             norm='l2', \n",
        "  #                             strip_accents = 'unicode',  \n",
        "  #                             ngram_range=(1, 2), \n",
        "  #                             analyzer = 'word',\n",
        "  #                             lowercase= True)\n",
        "  #vectorizer.fit(df[col])\n",
        "  X = pd.DataFrame.sparse.from_spmatrix(vectorizer.transform(df[col]))\n",
        "  df = df.join(X.add_prefix(col + '_vec_'))\n",
        "  df.drop(col,axis = 1)\n",
        "  return df\n",
        "\n",
        "def prepare(df, title_vectorizer, description_vectorizer):\n",
        "  t0 = datetime.datetime.now()\n",
        "  # only 17 missing so remove\n",
        "  df.nature_of_contract = df.nature_of_contract.fillna('empty')#df = df[~df['nature_of_contract'].isna()\n",
        "  # after deleting \n",
        "  df = df.reset_index()\n",
        "\n",
        "  # docid is completely unique so drop\n",
        "  \n",
        "\n",
        "  # titles have Germany-<city>:<title>\n",
        "  # Germany is in every row so remove, city & title can be split\n",
        "  df.title = df.title.str[8:] # remove 'Germany-' at start\n",
        "  df['city'] = pd.Series(df['title']).apply(split_left)\n",
        "  df['title'] = pd.Series(df['title']).apply(split_right)\n",
        "\n",
        "  oe = OrdinalEncoder()\n",
        "\n",
        "  oe_pd = oe.fit_transform(df[['publication_date']]) \n",
        "  df['enc_publication_date'] = oe_pd\n",
        "  df = df.drop('publication_date', axis = 1)\n",
        "\n",
        "  \n",
        "  df = OHE(df, 'contract_type')\n",
        "  #df = OHE(df, 'region')\n",
        "\n",
        "  # single country so useless\n",
        "  df = df.drop('country_name', axis = 1)\n",
        "  df = df.drop('country_code', axis = 1)\n",
        "\n",
        "  # most are missing - for the moment we will drop it\n",
        "  df = df.drop('value', axis = 1)\n",
        "\n",
        "  text_cols = ['title', 'description', 'awarding_authority']\n",
        "\n",
        "  print('time 1: ', (datetime.datetime.now()-t0).seconds)\n",
        "\n",
        "  for col_name in text_cols:\n",
        "    df[col_name] = df[col_name].apply(cleanPunc)\n",
        "    print('time 2: ', (datetime.datetime.now()-t0).seconds)\n",
        "    # Getting rid of the stopwords\n",
        "    # code changed from https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe\n",
        "    df[col_name] = df[col_name].apply((lambda x: ' '.join([word for word in x.split() if word not in (stop_words)])))\n",
        "    print('time 3: ', (datetime.datetime.now()-t0).seconds)\n",
        "    # stem / lemmatize words\n",
        "    df[col_name] = df[col_name].apply(stemSentence)\n",
        "    print('time 4: ', (datetime.datetime.now()-t0).seconds)\n",
        "\n",
        "#  #vectorise text\n",
        "  df = vectorise_col(df, 'title', title_vectorizer)\n",
        "  print('time 5: ', (datetime.datetime.now()-t0).seconds)\n",
        "  df = vectorise_col(df, 'description', description_vectorizer)\n",
        "  print('time 6: ', (datetime.datetime.now()-t0).seconds)\n",
        "\n",
        "  # for now drop to start analysis\n",
        "  df = df.drop(['sector','title','description', 'city', 'awarding_authority',\n",
        "                'index', 'nature_of_contract'], \n",
        "               axis = 1)\n",
        "  \n",
        "  if 'label' in df:\n",
        "    # parse label into multiple bits\n",
        "    df.label = df.label.astype(str)\n",
        "    df.label = df.label.apply(lambda x: '{0:0>9}'.format(x))\n",
        "    print('time 7: ', (datetime.datetime.now()-t0).seconds)\n",
        "    # this line takes ages\n",
        "    df_labels = pd.DataFrame(df.label.apply(lambda x: pd.Series(list(x)).astype(float)))\n",
        "    print('time 8: ', (datetime.datetime.now()-t0).seconds)\n",
        "    df_labels = df_labels.add_prefix('label_')\n",
        "    label_names = df_labels.columns\n",
        "    df = pd.concat((df, df_labels), axis = 1)\n",
        "    # don't need\n",
        "    df = df.drop(['category','label','docid']\n",
        "                 , axis = 1)\n",
        "    \n",
        "    return df, label_names\n",
        "  else:\n",
        "    return df\n",
        "  \n",
        "\n",
        "\n",
        "def getY(df, label_names):\n",
        "  Y = df[label_names]\n",
        "  X = df.drop(label_names, axis = 1)\n",
        "  return X, Y\n",
        "  \n",
        "\n",
        "def split(df, split1, split2):\n",
        "  train, test = train_test_split(df, test_size = split1, random_state = 42)\n",
        "  train, val = train_test_split(train, test_size = split2, random_state = 42)\n",
        "  return train, test, val\n",
        "\n",
        "def scale(X1, X2 = None, X3 = None):\n",
        "  scaler = StandardScaler()\n",
        "  cols = X1.columns\n",
        "  X1_scaled = pd.DataFrame(scaler.fit_transform(X1), columns= cols)\n",
        "  if not X2 is None and not X3 is None:\n",
        "    X2_scaled = pd.DataFrame(scaler.transform(X2), columns= cols)\n",
        "    X3_scaled = pd.DataFrame(scaler.transform(X3), columns= cols)\n",
        "    return X1_scaled, X2_scaled, X3_scaled\n",
        "\n",
        "def collapseLabel(x):\n",
        "  return int(''.join(x))\n",
        "\n",
        "def getPrediction(Y_pred, docid):\n",
        "  #Y_pred array, docid Series\n",
        "  docid = docid.reset_index()\n",
        "  Y_pred = Y_pred.astype(int)\n",
        "  Y_pred = Y_pred.astype(str)\n",
        "  Y_pred = pd.DataFrame(Y_pred)\n",
        "  Y_pred = pd.Series(Y_pred.apply(collapseLabel, axis = 1), name = 'label')\n",
        "  Y_pred = docid.join(Y_pred)\n",
        "  #Y_pred = Y_pred.drop('index',axis = 1) # docid is index\n",
        "  return Y_pred\n",
        "\n",
        "def fit_text_to_sequence(texts1, max_no_wrds, texts2 = None):\n",
        "  if texts2 == None:\n",
        "    texts = texts1\n",
        "  else:\n",
        "    texts = texts1.append(texts2)\n",
        "  tokenizer = Tokenizer(num_words = max_no_wrds)\n",
        "  tokenizer.fit_on_texts(texts)\n",
        "  return tokenizer\n",
        "\n",
        "def get_text_to_sequence(text, tokenizer, pad_len):\n",
        "  sequences = tokenizer.texts_to_sequences(text)\n",
        "  if pad_len != 0:\n",
        "    sequences = pad_sequences(sequences, maxlen = pad_len)\n",
        "  return sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7UjYgbSPpDh"
      },
      "source": [
        "texts_title = train.title.apply(split_right)\n",
        "texts_description = train.description\n",
        "texts_title = texts_title.apply(cleanPunc)\n",
        "texts_title = texts_title.apply(stemSentence)\n",
        "texts_description = texts_description.apply(cleanPunc)\n",
        "texts_description = texts_description.apply(stemSentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD37e1z4Ptm4",
        "outputId": "46f9a61f-f299-4ad4-a831-3e931ae2f49c"
      },
      "source": [
        "tokenizer_title = fit_text_to_sequence(texts_title, 2000)\n",
        "sequences_title = get_text_to_sequence(texts_title, tokenizer_title, 20)\n",
        "tokenizer_description = fit_text_to_sequence(texts_description, 5000)\n",
        "sequences_description = get_text_to_sequence(texts_description, tokenizer_title, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(98320, 20)\n",
            "(98320, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io-BmWqGPyeQ",
        "outputId": "8da58ebe-a820-48dc-a589-5a9b74f20b37"
      },
      "source": [
        "max_l = 0\n",
        "sum_l = 0\n",
        "for sequence in sequences_title:\n",
        "  l = len(sequence)\n",
        "  sum_l= sum_l+l\n",
        "  if max_l<l: max_l = l\n",
        "print('max len: ', max_l)\n",
        "print('mean len: ', sum_l/len(sequences_title))\n",
        "\n",
        "max_l = 0\n",
        "sum_l = 0\n",
        "for sequence in sequences_description:\n",
        "  l = len(sequence)\n",
        "  sum_l= sum_l+l\n",
        "  if max_l<l: max_l = l\n",
        "print('max len: ', max_l)\n",
        "print('mean len: ', sum_l/len(sequences_description))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max len:  20\n",
            "mean len:  20.0\n",
            "max len:  100\n",
            "mean len:  100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqll366-P0hI"
      },
      "source": [
        "print(test.shape)\n",
        "# fit vectoriser on both sets so the train and test sets will have the same shape\n",
        "title_vectorizer = fit_vectorizer(train, test, 'title', 500) \n",
        "description_vectorizer = fit_vectorizer(train, test, 'description', 700)\n",
        "train, label_names = prepare(train, title_vectorizer, description_vectorizer)\n",
        "test = prepare(test, title_vectorizer, description_vectorizer)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lYPi-HPP3SQ",
        "outputId": "ceaf10ce-1924-430c-c580-3dadea264ecd"
      },
      "source": [
        "print(train.head())\n",
        "print(test.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   enc_publication_date  contract_type_award  ...  label_7  label_8\n",
            "0                 199.0                  1.0  ...      0.0      0.0\n",
            "1                 222.0                  0.0  ...      0.0      0.0\n",
            "2                  30.0                  0.0  ...      0.0      0.0\n",
            "3                 154.0                  0.0  ...      0.0      0.0\n",
            "4                  50.0                  1.0  ...      0.0      0.0\n",
            "\n",
            "[5 rows x 1298 columns]\n",
            "        docid  enc_publication_date  ...  description_vec_892  description_vec_893\n",
            "0  2535443526                 218.0  ...             0.000000                  0.0\n",
            "1  2487195007                 195.0  ...             0.000000                  0.0\n",
            "2  2573583192                 237.0  ...             0.000000                  0.0\n",
            "3  2213029015                  34.0  ...             0.000000                  0.0\n",
            "4  2218957610                  37.0  ...             0.314131                  0.0\n",
            "\n",
            "[5 rows x 1290 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k08qT4NwP5xY",
        "outputId": "038bb581-5673-4c49-927c-d561b9c5ffca"
      },
      "source": [
        "cols = [col for col in train.columns if 'title' in col]\n",
        "print(len(cols))\n",
        "cols = [col for col in train.columns if 'description' in col]\n",
        "print(len(cols))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "392\n",
            "894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3X15ZuzS-iS"
      },
      "source": [
        "df_train, df_test, df_val = split(train, .2, .25)\n",
        "X_train, Y_train = getY(df_train, label_names)\n",
        "X_test, Y_test = getY(df_test, label_names)\n",
        "X_val, Y_val = getY(df_val, label_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29VhYLNoTC1J"
      },
      "source": [
        "X_train_scaled, X_test_scaled, X_val_scaled = scale(X_train, X_test, X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knfYckgfTIth"
      },
      "source": [
        "#Scaling the test data so that we can make predictions on it\n",
        "\n",
        "test2 = test.drop(['docid'],axis=1)\n",
        "cols = test2.columns\n",
        "scaler = StandardScaler()\n",
        "test_scaled = pd.DataFrame(scaler.fit_transform(test2), columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyuWza3STMCJ",
        "outputId": "87b493ab-6bce-4278-eb45-fc407c7fd4a5"
      },
      "source": [
        "t0 = datetime.datetime.now()\n",
        "ovr = OneVsRestClassifier(GaussianNB())\n",
        "print((datetime.datetime.now()-t0).seconds)\n",
        "clf = ovr.fit(X_train_scaled,Y_train)\n",
        "print((datetime.datetime.now()-t0).seconds)\n",
        "clv_pred = clf.predict(X_test_scaled)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N8q21YXTQFw",
        "outputId": "25b997fe-2795-408c-e4a0-10f7df419a59"
      },
      "source": [
        "#Get a f1 score of 0.60128 when testing with the seperated data from the training data\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(Y_test,clv_pred, average= 'weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6012814281429145"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8oWmz7dTTx4"
      },
      "source": [
        "#Getting predictions for kaggle for the baseline machine learning model\n",
        "#Kaggle score was 0.58151\n",
        "\n",
        "pred = clf.predict(test_scaled)\n",
        "pred = pred.round()\n",
        "pred\n",
        "\n",
        "Predictions_Machine_Learning_Baseline = getPrediction(pred, test.docid)\n",
        "Predictions_Machine_Learning_Baseline = Predictions_Machine_Learning_Baseline.drop(['index'],axis = 1)\n",
        "Predictions_Machine_Learning_Baseline\n",
        "\n",
        "from google.colab import files\n",
        "Predictions_Machine_Learning_Baseline.to_csv('Machine_Learning_Baseline_Predictions.csv') \n",
        "files.download('Machine_Learning_Baseline_Predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5KpXel5TWEI"
      },
      "source": [
        "#Tryin to get grid search working for number of layers and number of neurons\n",
        "#Code taken from lab 2 solutions\n",
        "\n",
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[1289]):\n",
        "\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "  for layer in range(n_hidden):\n",
        "    model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "  model.add(keras.layers.Dense(9, activation=\"sigmoid\"))\n",
        "  \n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6emJVWgtTb7Z"
      },
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uea2_CJbTelp"
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "history = keras_reg.fit(X_train_scaled, Y_train, epochs=100, validation_data=(X_val_scaled, Y_val), verbose=0, callbacks=[early_stopping_cb])\n",
        "pred = keras_reg.predict(X_test_scaled)\n",
        "pred = pred.round()\n",
        "f1_score_test = f1_score(Y_test, pred, average= 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vgiIKoOTh3p"
      },
      "source": [
        "#Choosing the parameters to try\n",
        "\n",
        "parameters = {\n",
        "    \"n_hidden\":[(0),(1),(2),(3),(4)],\n",
        "    \"n_neurons\":np.arange(20,100),\n",
        "    \"learning_rate\": [(3e-2),(3e-3),(3e-4)]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cKlNtDSTliR"
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, parameters, n_iter=10, cv=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFRyno_wTmDR"
      },
      "source": [
        "rnd_search_cv.fit(X_train_scaled, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABl45pZyToC5"
      },
      "source": [
        "print(rnd_search_cv.best_params_)\n",
        "print(rnd_search_cv.best_score_)\n",
        "\n",
        "#Best parameters, 86 neurons, 4 hidden layers, 0.003 learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rvdfBbpTqmR"
      },
      "source": [
        "#Creating a model with the above parameters\n",
        "\n",
        "deep_model_best_param = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[1289]),\n",
        "    keras.layers.Dense(86, activation=\"relu\"),\n",
        "    keras.layers.Dense(86, activation=\"relu\"),\n",
        "    keras.layers.Dense(86, activation=\"relu\"),\n",
        "    keras.layers.Dense(86, activation=\"relu\"),\n",
        "    keras.layers.Dense(9, activation=\"sigmoid\")     \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "634ik1thT0Vp"
      },
      "source": [
        "#Compiling the model\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.003)\n",
        "deep_model_best_param.compile(loss=\"binary_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRK5TzblT3lh"
      },
      "source": [
        "#Fitting the model\n",
        "\n",
        "Deep_Model = deep_model_best_param.fit(X_train_scaled, Y_train, epochs=30, validation_data=(X_val_scaled,Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy5yFk7nT4MB"
      },
      "source": [
        "#Getting the f1 score for the deep model with the best parameters\n",
        "#Gave a f1 score of 0.60128\n",
        "\n",
        "pred = deep_model_best_param.predict(X_test_scaled)\n",
        "f1_score(Y_test,clv_pred, average= 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD_VXVoGT7B5"
      },
      "source": [
        "#Getting predictions for the model using the test dataframe\n",
        "\n",
        "#test2 = test.drop(['docid'],axis=1)\n",
        "#cols = test2.columns\n",
        "#scaler = StandardScaler()\n",
        "#test_scaled = pd.DataFrame(scaler.fit_transform(test2), columns=cols)\n",
        "pred = deep_model_best_param.predict(test_scaled)\n",
        "pred = pred.round()\n",
        "\n",
        "Predictions_Deep_Model = getPrediction(pred, test.docid)\n",
        "Predictions_Deep_Model = Predictions_Deep_Model.drop(['index'],axis = 1)\n",
        "\n",
        "from google.colab import files\n",
        "Predictions_Deep_Model.to_csv('Deep_Model_Predictions.csv') \n",
        "files.download('Deep_Model_Predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAkbQ0kxT9Aq"
      },
      "source": [
        "##Code for LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0b8sAtgUGR3"
      },
      "source": [
        "#Code was adapted from https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35 (Reference 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IchX__mSUPD6",
        "outputId": "cf7df9a7-e8b7-4985-b5dd-429b8f002221"
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk.corpus \n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "STOPWORDS = stopwords.words(['english'])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqnY7V61UQQS"
      },
      "source": [
        "train = pd.read_csv('/content/german-contracts-train.csv')\n",
        "test = pd.read_csv('/content/german-contracts-test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCyM-eXhURtK"
      },
      "source": [
        "train = train.drop(['nature_of_contract'], axis = 1)\n",
        "test = test.drop(['nature_of_contract'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxoCZ2_KUWIh"
      },
      "source": [
        "#Hyperparameters\n",
        "\n",
        "vocab_size = 5000\n",
        "embedding_dim = 64\n",
        "max_length = 7\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKXFasHrUYCB"
      },
      "source": [
        "def split_right(s):\n",
        "  n = s.find(':')\n",
        "  a = s[n+1:]\n",
        "  return a\n",
        "\n",
        "def split_left(s):\n",
        "  n = s.find(':')\n",
        "  a = s[:n]\n",
        "  return a\n",
        "\n",
        "def OHE(df, col):\n",
        "  # one hot encode column (col) in dataframe (df) then replace original column \n",
        "  # with one hot encoded column\n",
        "  ohe = OneHotEncoder(sparse = False)\n",
        "  ohe_values = ohe.fit_transform(df[[col]])\n",
        "  ohe_cols = [col + '_' + s for s in ohe.categories_]\n",
        "  df_ohe_values = pd.DataFrame(ohe_values,\n",
        "                               columns = np.ndarray.flatten(np.array(ohe_cols)))\n",
        "  df = pd.concat((df, df_ohe_values), axis = 1)\n",
        "  df = df.drop(col, axis = 1)\n",
        "  return df\n",
        "\n",
        "def prepare(df):\n",
        "  # only 17 missing so remove\n",
        "  ##df = df[~df['nature_of_contract'].isna()]\n",
        "  ##df['the_index'] = df.index\n",
        "  # after deleting \n",
        "  ##df = df.reset_index()\n",
        "\n",
        "  # titles have Germany-<city>:<title>\n",
        "  # Germany is in every row so remove, city & title can be split\n",
        "  df.title = df.title.str[8:] # remove 'Germany-' at start\n",
        "  df['city'] = pd.Series(df['title']).apply(split_left)\n",
        "  df['title'] = pd.Series(df['title']).apply(split_right)\n",
        "\n",
        "  oe = OrdinalEncoder()\n",
        "\n",
        "  oe_pd = oe.fit_transform(df[['publication_date']]) \n",
        "  df['enc_publication_date'] = oe_pd\n",
        "  df = df.drop('publication_date', axis = 1)\n",
        "\n",
        "  \n",
        "  df = OHE(df, 'contract_type')\n",
        "  #df = OHE(df, 'nature_of_contract')\n",
        "  #df = OHE(df, 'region')\n",
        "\n",
        "  # single country so useless\n",
        "  df = df.drop('country_name', axis = 1)\n",
        "  df = df.drop('country_code', axis = 1)\n",
        "\n",
        "  # most are missing - for the moment we will drop it\n",
        "  df = df.drop('value', axis = 1)\n",
        "\n",
        "  if 'label' in df:\n",
        "    # parse label into multiple bits\n",
        "    df.label = df.label.astype(str)\n",
        "    df.label = df.label.apply(lambda x: '{0:0>9}'.format(x))\n",
        "    # this line takes ages\n",
        "    df_labels = pd.DataFrame(df.label.apply(lambda x: pd.Series(list(x)).astype(float)))\n",
        "    df_labels = df_labels.add_prefix('label_')\n",
        "    df = pd.concat((df, df_labels), axis = 1)\n",
        "    # don't need labels or categories\n",
        "    df = df.drop('label', axis = 1)\n",
        "    df = df.drop('category', axis = 1)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "LatEvEsoUbzJ",
        "outputId": "e7278465-8efa-4df5-a2de-361597a358b9"
      },
      "source": [
        "train = prepare(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>sector</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>awarding_authority</th>\n",
              "      <th>city</th>\n",
              "      <th>enc_publication_date</th>\n",
              "      <th>contract_type_award</th>\n",
              "      <th>contract_type_notice</th>\n",
              "      <th>label_0</th>\n",
              "      <th>label_1</th>\n",
              "      <th>label_2</th>\n",
              "      <th>label_3</th>\n",
              "      <th>label_4</th>\n",
              "      <th>label_5</th>\n",
              "      <th>label_6</th>\n",
              "      <th>label_7</th>\n",
              "      <th>label_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2493527426</td>\n",
              "      <td>public</td>\n",
              "      <td>Cleaning services</td>\n",
              "      <td>Unterhalts- und Glasreinigung.\\n</td>\n",
              "      <td>Staatliches Baumanagement Ems-Weser</td>\n",
              "      <td>Wilhelmshaven</td>\n",
              "      <td>199.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2538215982</td>\n",
              "      <td>public</td>\n",
              "      <td>Engineering-design services for traffic insta...</td>\n",
              "      <td>ABS Karlsruhe-Stuttgart-Nürnberg-Leipzig/Dresd...</td>\n",
              "      <td>DB Netz AG</td>\n",
              "      <td>Dresden</td>\n",
              "      <td>222.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2204943443</td>\n",
              "      <td>public</td>\n",
              "      <td>Heating, ventilation and air-conditioning ins...</td>\n",
              "      <td>Nach Fertigstellung des ersten Bauabschnitts e...</td>\n",
              "      <td>Große Kreisstadt Germering</td>\n",
              "      <td>Germering</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2417769175</td>\n",
              "      <td>public</td>\n",
              "      <td>Boards</td>\n",
              "      <td>Einrichtung Tafelsystem.\\n</td>\n",
              "      <td>Gemeinde Limbach</td>\n",
              "      <td>Limbach</td>\n",
              "      <td>154.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2242098706</td>\n",
              "      <td>public</td>\n",
              "      <td>Landscaping work for green areas</td>\n",
              "      <td>Im Projekt Neubau Filiale in Dortmund wird das...</td>\n",
              "      <td>Deutsche Bundesbank, Beschaffungszentrum</td>\n",
              "      <td>Frankfurt-on-Main</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        docid  sector  ... label_7 label_8\n",
              "0  2493527426  public  ...     0.0     0.0\n",
              "1  2538215982  public  ...     0.0     0.0\n",
              "2  2204943443  public  ...     0.0     0.0\n",
              "3  2417769175  public  ...     0.0     0.0\n",
              "4  2242098706  public  ...     0.0     0.0\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x16Ea4EsUgBx"
      },
      "source": [
        "test = prepare(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ianMNC4uUiE5",
        "outputId": "655f589b-c448-4b77-d5f4-29a2bec94efe"
      },
      "source": [
        "test.title"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                Software-related services\n",
              "1         Architectural, construction, engineering and ...\n",
              "2                              Integrated circuit packages\n",
              "3                      Construction work for swimming pool\n",
              "4                            Architectural design services\n",
              "                               ...                        \n",
              "24576     Architectural, engineering and planning services\n",
              "24577     Architectural, construction, engineering and ...\n",
              "24578                       Plumbing and drain-laying work\n",
              "24579     Works for complete or part construction and c...\n",
              "24580                             School cleaning services\n",
              "Name: title, Length: 24581, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu_VDm1tU7k7"
      },
      "source": [
        "title = train.title\n",
        "label = train.drop(['docid', 'sector', 'title', 'description',  \n",
        "                          'awarding_authority', 'city', \n",
        "                          'enc_publication_date', 'contract_type_award', \n",
        "                          'contract_type_notice'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj1oF3mBU9cJ"
      },
      "source": [
        "import re\n",
        "\n",
        "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/|-]',r' ',cleaned)\n",
        "    cleaned = cleaned.strip()\n",
        "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
        "    return cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN9wQ0uIVCQS",
        "outputId": "ef199ac5-257e-4a03-baa0-ff9b9b3d97fe"
      },
      "source": [
        "#Cleaning the title list\n",
        "\n",
        "title= title.apply(cleanPunc)\n",
        "title"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                        Cleaning services\n",
              "1        Engineering design services for traffic instal...\n",
              "2        Heating  ventilation and air conditioning inst...\n",
              "3                                                   Boards\n",
              "4                         Landscaping work for green areas\n",
              "                               ...                        \n",
              "98315                  Construction work for swimming pool\n",
              "98316    Research and testing facilities construction work\n",
              "98317                  Switching station installation work\n",
              "98318                                    Construction work\n",
              "98319                           Survey conduction services\n",
              "Name: title, Length: 98320, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WObAWbrvVEep",
        "outputId": "3199634a-e263-4b10-b9ea-a664b5fb7c12"
      },
      "source": [
        "#Applying stopwords to title list\n",
        "\n",
        "title = title.apply((lambda x: ' '.join([word for word in x.split() if word not in (STOPWORDS)])))\n",
        "title"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                        Cleaning services\n",
              "1        Engineering design services traffic installations\n",
              "2        Heating ventilation air conditioning installat...\n",
              "3                                                   Boards\n",
              "4                             Landscaping work green areas\n",
              "                               ...                        \n",
              "98315                      Construction work swimming pool\n",
              "98316        Research testing facilities construction work\n",
              "98317                  Switching station installation work\n",
              "98318                                    Construction work\n",
              "98319                           Survey conduction services\n",
              "Name: title, Length: 98320, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpQll7zHWKND",
        "outputId": "8de4a7db-0cee-4e65-d15f-b2b5ed349993"
      },
      "source": [
        "#Setting up validation data\n",
        "\n",
        "train_size = int(len(title) * 0.8)\n",
        "\n",
        "train_title = title[0: train_size]\n",
        "train_label = label[0: train_size]\n",
        "\n",
        "validation_title = title[train_size:]\n",
        "validation_label = label[train_size:]\n",
        "\n",
        "train_size1 = int(len(train_title) * 0.9)\n",
        "\n",
        "train_title = title[0: train_size1]\n",
        "train_label = label[0: train_size1]\n",
        "\n",
        "test_title = title[train_size1:]\n",
        "test_label = label[train_size1:]\n",
        "\n",
        "\n",
        "print(train_size)\n",
        "print(len(train_title))\n",
        "print(len(train_label))\n",
        "print(len(validation_title))\n",
        "print(len(validation_label))\n",
        "print(len(test_title))\n",
        "print(len(test_label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78656\n",
            "70790\n",
            "70790\n",
            "19664\n",
            "19664\n",
            "27530\n",
            "27530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ray2hXj_WOey"
      },
      "source": [
        "#Tokenizing all the words in the title\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_title)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt5r6d1CWQsy",
        "outputId": "08054a7b-c93e-4496-b849-93f70a6f6993"
      },
      "source": [
        "dict(list(word_index.items())[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<OOV>': 1,\n",
              " 'architectural': 8,\n",
              " 'building': 10,\n",
              " 'construction': 4,\n",
              " 'engineering': 5,\n",
              " 'installation': 7,\n",
              " 'related': 9,\n",
              " 'services': 2,\n",
              " 'work': 3,\n",
              " 'works': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zWeM7DGWjmy"
      },
      "source": [
        "#Changing these tokens into a list of sequences\n",
        "#Making all the sequences in train, validation and test sequences the same length by padding\n",
        "#Made the max length of a padded sequence 7 as I thought it was a good average for it\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_title)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_title)\n",
        "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_title)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rD8pHEvWlna"
      },
      "source": [
        "#Making the LSTM model now\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
        "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
        "    tf.keras.layers.Dense(9, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRSqkk9xWsfq"
      },
      "source": [
        "#Compiling the model\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfpC7tGDWuAy"
      },
      "source": [
        "#Fitting the model\n",
        "\n",
        "history = model.fit(train_padded, train_label, epochs=30, validation_data=(validation_padded, validation_label), verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76pAfzcbW1Gq"
      },
      "source": [
        "#Getting f1 score for the padded test data\n",
        "\n",
        "pred = model.predict(test_padded)\n",
        "pred = pred.round()\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(test_label, pred, average= 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZ90gcTW3Gq"
      },
      "source": [
        "def collapseLabel(x):\n",
        "    return int(''.join(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsqijy6_W4sK"
      },
      "source": [
        "def getPrediction(Y_pred, docid):\n",
        "  #Y_pred array, docid Series\n",
        "  docid = docid.reset_index()\n",
        "  Y_pred = Y_pred.astype(int)\n",
        "  Y_pred = Y_pred.astype(str)\n",
        "  Y_pred = pd.DataFrame(Y_pred)\n",
        "  Y_pred = pd.Series(Y_pred.apply(collapseLabel, axis = 1), name = 'label')\n",
        "  Y_pred = docid.join(Y_pred)\n",
        "  #Y_pred = Y_pred.drop('index',axis = 1) # docid is index\n",
        "  return Y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ-GtE_VW6Dq"
      },
      "source": [
        "title_test_final = test.title\n",
        "title_test_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyIvAUCWW7iR"
      },
      "source": [
        "#Cleaning the test data\n",
        "\n",
        "title_test_final = title_test_final.apply(cleanPunc)\n",
        "title_test_final = title_test_final.apply((lambda x: ' '.join([word for word in x.split() if word not in (STOPWORDS)])))\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(title_test_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIK_YUcoW8xJ"
      },
      "source": [
        "#Padding the test data\n",
        "\n",
        "title_test_final_sequences = tokenizer.texts_to_sequences(title_test_final)\n",
        "title_test_final_padded = pad_sequences(title_test_final_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw3O9Q6KW-M5"
      },
      "source": [
        "#Getting predictions with the test data\n",
        "\n",
        "pred = model.predict(title_test_final_padded)\n",
        "pred = pred.round()\n",
        "pred\n",
        "\n",
        "Predictions_LSTM = getPrediction(pred, test.docid)\n",
        "Predictions_LSTM = Predictions_LSTM.drop(['index'],axis = 1)\n",
        "Predictions_LSTM\n",
        "\n",
        "from google.colab import files\n",
        "Predictions_LSTM.to_csv('LSTM_Predictions.csv') \n",
        "files.download('LSTM_Predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZOJC8SRO1Z2"
      },
      "source": [
        "#BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "bE29y-X3TtS8",
        "outputId": "0f4b3ec4-e90c-4bb3-8e20-72bd099bbec7"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() #select kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d4460c6d-3e43-411f-b44d-f1bedfee5c2b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d4460c6d-3e43-411f-b44d-f1bedfee5c2b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"joshmurphy1\",\"key\":\"bb8463773ae7ac48e9f681ece9e94f9a\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRL8NxS0Tkci",
        "outputId": "bab3b213-9fde-42cf-9f14-d5b0632327a0"
      },
      "source": [
        "# skip this cell if you have directly downloaded csv\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c cs98x-dl-task2-contract-clasification\n",
        "!unzip german-contracts-test.csv.zip\n",
        "!unzip german-contracts-train.csv.zip\n",
        "!rm german-contracts-test.csv.zip\n",
        "!rm german-contracts-train.csv.zip\n",
        "# download city data from github to analyse part of title\n",
        "#!git clone https://github.com/pensnarik/german-cities.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading german-contracts-train.csv.zip to /content\n",
            " 57% 9.00M/15.9M [00:00<00:00, 30.3MB/s]\n",
            "100% 15.9M/15.9M [00:00<00:00, 40.2MB/s]\n",
            "Downloading german-contracts-sample-submission_1.csv to /content\n",
            "  0% 0.00/504k [00:00<?, ?B/s]\n",
            "100% 504k/504k [00:00<00:00, 163MB/s]\n",
            "Downloading german-contracts-test.csv.zip to /content\n",
            "  0% 0.00/3.83M [00:00<?, ?B/s]\n",
            "100% 3.83M/3.83M [00:00<00:00, 124MB/s]\n",
            "Archive:  german-contracts-test.csv.zip\n",
            "  inflating: german-contracts-test.csv  \n",
            "Archive:  german-contracts-train.csv.zip\n",
            "  inflating: german-contracts-train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viy2tAaBNB6F"
      },
      "source": [
        "train = pd.read_csv('/content/german-contracts-train.csv')\n",
        "test = pd.read_csv('/content/german-contracts-test.csv')\n",
        "#cities = pd.read_json('/content/german-cities/germany.json')\n",
        "#cities = cities.drop(['coords'], axis = 1) # don't ever see us using this\n",
        "#cities = cities[~(cities.population == '0 2103')] # bad value\n",
        "#cities.population = cities.population.astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilx4x7Vfl1sb"
      },
      "source": [
        "###Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4LGcN-AyG3s",
        "outputId": "c38ad2cf-2ce1-4041-bfa1-3bd138626d47"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 25.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=f2a5346fe70c6a1934d1e87513e40ea7a905a35dbfcd138315398c80e94b8869\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d2mzp7lxzae"
      },
      "source": [
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aPio7Mfy-L1"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBMhFraJl6Uc"
      },
      "source": [
        "###Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai0Lh9SjdLoF"
      },
      "source": [
        "def joincols_to_label(cols, label = train[\"label\"]):\n",
        "  label = label.astype(str).apply(lambda x: '{0:0>9}'.format(x))\n",
        "  df_labels = pd.DataFrame(label.apply(lambda x: pd.Series(list(x)).astype(float)))\n",
        "  df_labels = df_labels.add_prefix('label_')\n",
        "  df = pd.concat((cols, df_labels), axis = 1)\n",
        "  return(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOjNj05NRdc9"
      },
      "source": [
        "#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "#average=macro?\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhOwrerwf_DH"
      },
      "source": [
        "def tokenise_and_split(df, val_size):\n",
        "  x = tokenizer(\n",
        "    text=df.iloc[:,0].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = False,\n",
        "    verbose = True)\n",
        "  \n",
        "  x_train = tf.convert_to_tensor(x[\"input_ids\"][:-val_size], name=\"input_ids\")\n",
        "  x_val = tf.convert_to_tensor(x[\"input_ids\"][-2*val_size:-val_size], name=\"input_ids\")\n",
        "  x_test = tf.convert_to_tensor(x[\"input_ids\"][-val_size:], name=\"input_ids\")\n",
        "\n",
        "  return x_train, x_val, x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zEOwQdFh-zp"
      },
      "source": [
        "def label_split(df, val_size):\n",
        "  y={}\n",
        "  for i in range(0, 9):\n",
        "    y[\"lab{}\".format(i)] = df['label_{}'.format(i)]\n",
        "  \n",
        "  y_train = {}\n",
        "  y_val = {}\n",
        "  y_test = {}\n",
        "\n",
        "  for key in y:\n",
        "    y_train[key] = y[key][:-val_size]\n",
        "    y_val[key] = y[key][-2*val_size:-val_size]\n",
        "    y_test[key] = y[key][-10000:]\n",
        "\n",
        "  return y_train, y_val, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_hfEevvU_dv"
      },
      "source": [
        "###Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367,
          "referenced_widgets": [
            "0202d1dca65c4ea080a32ee279bab6d2",
            "465c5632201146fda431b438799bd287",
            "e70693c7df5e47bdb912b19df7df696f",
            "e078ecbf5810444888c9aa2024884cfe",
            "cf5d863ac0184d9e8c2a97a00162242d",
            "b5e7b9678cf5474c9b3bf869fb299ca1",
            "b11d1a13684d4d038b7a0a36dfedd4c4",
            "b6255e93757e47c3a3f26716c8328cc3",
            "50240b264003435fa9016827f9ceb487",
            "4550873bf0364a138fe98687bf1498bf",
            "23ecfd2b5f31424386ecb51105152643",
            "4879be5025224fac8accdd11cc1ac6ad",
            "5ae2f0ff5a3c41f5873b032cf06467eb",
            "78909ffffe344a359ca265b377afe721",
            "8dbc1dca607d4775ae3a1fce0a1fcbb8",
            "89881ebe0d824afd888f4757214e304a",
            "d2dd653f6ba54d4ab9753b94e517c523",
            "263a8a77d1324d6e89ebaf5460124919",
            "0571117c5d1c4f3bac129471c8861dac",
            "5b13e1a161fd47ae9c30c2c6c3c37d14",
            "b90ec8175e3d4fd6bfb23dc35cc1040a",
            "73c8f72e22b74e4da04c73380dfd99ea",
            "744f89110c7545bd8fd615065d535c11",
            "8b7be642f7964c76b70ca3b8f3801c57",
            "2a0614461b8e4288b8b66785ef5c405d",
            "5916eed760c648e5801ce67d3b794ebe",
            "6ced2c02c81142b0bc3512d6f99c957d",
            "52a5c2c0141b45f1950c16883ff2ee0a",
            "0d7b00fd546e42278afe570c628aba1b",
            "a005bdf9f4924c40b3764c4f0b25f989",
            "bcb240e5d06d4b00aedcd9258c36dab9",
            "d10207c93bea42a58628e60e66f40d6c",
            "04ccc20b4ab74723a918a680b14bacd4",
            "a06adab86952482b981cb1bb9e890246",
            "aba6584b92df402faadd2e4d0b8a6cc2",
            "1de25366b45f4974bbb9491af4768c16",
            "4724337427e3495bbd5ffd8753083cc1",
            "fa015bb2951545c5939d31708b3cd11f",
            "dc8194a57d9144d8bc072f6c2076ad4a",
            "c40bec67a11c42df997c4d037acf9b88"
          ]
        },
        "id": "zvbPVXqdyAii",
        "outputId": "f1627e1d-db1c-49af-e21e-5c1282e13f10"
      },
      "source": [
        "# Name BERT Model\n",
        "model_name = 'bert-base-uncased'\n",
        "# Max length of tokens (for description only)\n",
        "max_length = 100\n",
        "# Load transformers config and set output_hidden_states to False\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "config.output_hidden_states = False\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
        "# Load the Transformers BERT model\n",
        "transformer_model = TFBertModel.from_pretrained(model_name, config = config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0202d1dca65c4ea080a32ee279bab6d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50240b264003435fa9016827f9ceb487",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2dd653f6ba54d4ab9753b94e517c523",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a0614461b8e4288b8b66785ef5c405d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04ccc20b4ab74723a918a680b14bacd4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDhstXIEdxlJ"
      },
      "source": [
        "class BERTClass(keras.Model):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.bert = transformer_model.layers[0]\n",
        "    self.dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "    self.outputted={}\n",
        "    \n",
        "    for i in range(0, 9):\n",
        "      self.outputted[\"lab{}\".format(i)] = Dense(units=1, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='lab{}'.format(i), activation=\"sigmoid\")\n",
        "      \n",
        "    \n",
        "  def call(self, inputs):\n",
        "    \n",
        "    bert_model = self.bert(inputs)[1]\n",
        "    pooled_output = self.dropout(bert_model, training=True)\n",
        "    \n",
        "    outputted = {}\n",
        "    for i in range(0, 9):\n",
        "      outputted[\"lab{}\".format(i)] = self.outputted[\"lab{}\".format(i)](pooled_output)\n",
        "    \n",
        "    return{\"lab0\":outputted[\"lab0\"],\n",
        "           \"lab1\":outputted[\"lab1\"],\n",
        "           \"lab2\":outputted[\"lab2\"],\n",
        "           \"lab3\":outputted[\"lab3\"],\n",
        "           \"lab4\":outputted[\"lab4\"],\n",
        "           \"lab5\":outputted[\"lab5\"],\n",
        "           \"lab6\":outputted[\"lab6\"],\n",
        "           \"lab7\":outputted[\"lab7\"],\n",
        "           \"lab8\":outputted[\"lab8\"]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D15KOB8nV86E"
      },
      "source": [
        "###Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8ad5EwSef8j"
      },
      "source": [
        "bert_df_title = joincols_to_label(train[\"title\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a3pbtXyhH5A"
      },
      "source": [
        "val_size = 10000\n",
        "x_train, x_val, x_test = tokenise_and_split(bert_df_title, val_size)\n",
        "y_train, y_val, y_test = label_split(bert_df_title, val_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqqbXmrCdyBC"
      },
      "source": [
        "bert = transformer_model.layers[0]\n",
        "input_ids = Input(shape=(46,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "bert_model = bert(inputs)[1]\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(bert_model, training=False)\n",
        "#output\n",
        "outputs = {}\n",
        "for i in range(0, 9):\n",
        "  outputs[\"lab{}\".format(i)] = Dense(units=1, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='lab{}'.format(i), activation=\"sigmoid\")(pooled_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-Veti-IepM0"
      },
      "source": [
        "mod2 = BERTClass()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUiRVnV7dyBD"
      },
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "# Set loss and metrics\n",
        "loss = {x: BinaryCrossentropy(from_logits = True) for x in outputs}\n",
        "metric = {x: f1_m for x in outputs}#, {x :f1_m for x in outputs}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IwpYLHEdyBD"
      },
      "source": [
        "# Compile the model\n",
        "mod2.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "2ey5VdjBdyBE",
        "outputId": "75b2e4f8-8d83-452a-f1d6-092142a0f27c"
      },
      "source": [
        "history = mod2.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    validation_data = (x_val, y_val),\n",
        "    #callbacks = [tensorboard_cb, checkpoint_cb],\n",
        "    batch_size=64,\n",
        "    epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "   1/1380 [..............................] - ETA: 20:59:35 - loss: 6.3867 - lab0_loss: 1.0285 - lab1_loss: 0.7231 - lab2_loss: 0.7142 - lab3_loss: 0.5570 - lab4_loss: 0.5316 - lab5_loss: 0.7344 - lab6_loss: 0.6344 - lab7_loss: 0.6781 - lab8_loss: 0.7855 - lab0_f1_m: 0.2222 - lab1_f1_m: 0.0000e+00 - lab2_f1_m: 0.0851 - lab3_f1_m: 0.0000e+00 - lab4_f1_m: 0.0000e+00 - lab5_f1_m: 0.0000e+00 - lab6_f1_m: 0.0000e+00 - lab7_f1_m: 0.0000e+00 - lab8_f1_m: 0.0656"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-1a33202b1290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#callbacks = [tensorboard_cb, checkpoint_cb],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     epochs=10)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwARU7ZfCIKl"
      },
      "source": [
        "y_test_pred = mod2.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRj7FsiXPQ1L"
      },
      "source": [
        "y_test_df = pd.DataFrame.from_dict(y_test)\n",
        "y_test_array = y_test_df.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPvbtPlLO3G8",
        "outputId": "2a341e17-1b1d-4bbf-b111-4c93d2c7eb2f"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test_array, pred_to_arr(y_test_pred), average= 'weighted')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9557397011049106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o32yE6KD-IbB"
      },
      "source": [
        "model.save_weights(\"bert_weights\", save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwI3vytGVQbc"
      },
      "source": [
        "### Test Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2gc58Be0Xnh"
      },
      "source": [
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x2 = tokenizer(\n",
        "    text=test[\"title\"].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=46,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = False,\n",
        "    verbose = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1FEJzeJQqkY"
      },
      "source": [
        "x3 = tf.convert_to_tensor(np.pad(x2[\"input_ids\"].numpy(), ((0, 0), (0, 4)), 'constant'), name=\"input_ids\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0ZPFsPm0GS2"
      },
      "source": [
        "predictions = mod2.predict(x={'input_ids': x3})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLKoLFnC80Hj"
      },
      "source": [
        "def pred_to_arr(predictions, tofile=False, filename = None):\n",
        "  predarray=[]\n",
        "  for key in predictions:\n",
        "    predarray.append(predictions[key].round())\n",
        "\n",
        "  preds = np.concatenate(predarray, axis=1)\n",
        "  #pred_list = [\"\".join(i) for i in preds.astype(int).astype(str)]\n",
        "  if tofile == True:\n",
        "    pred_list = [\"\".join(i) for i in preds.astype(int).astype(str)]\n",
        "    pred_series = pd.DataFrame({'label':pred_list})\n",
        "      ##type(test[\"docid\"])\n",
        "    docid = test[\"docid\"].to_frame()\n",
        "    prediction_output = docid.join(pred_series)\n",
        "    #return(prediction_output)\n",
        "    prediction_output.to_csv(filename, index=\"False\")\n",
        "    files.download(filename)\n",
        "  else:\n",
        "    return(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FapwGxvH9fHo",
        "outputId": "4dfb5dd7-6453-41e9-da17-65de7c423f1a"
      },
      "source": [
        "pred_to_csv(predictions, tofile=True, filename=\"bert_10_title_class_dropout.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e556df4f-3166-4a4e-ba94-4382935c0dda\", \"bert_10_title_class_dropout.csv\", 652590)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}